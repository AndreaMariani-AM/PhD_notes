
# Linear_algebra_lesson
Topic: #Statistics #Math #LinearAlgebra
Date: 2022-06-03


---

## Summary
Coursera course on mathmatics for machine learning, can be found [here](https://www.coursera.org/learn/linear-algebra-machine-learning?courseSlug=linear-algebra-machine-learning&showOnboardingModal=checkAndRedirect&specialization=mathematics-machine-learning)

## Notes
- in a funciton like this one: $\large 10a + 3b = 10$ numbers are called *constant linear coefficients*, that relate the *input variables* $a$ and $b$ to the output 10
- Vectors are represented with square brackets, matrices with round brackets
- $\Large \mu$ this is mu, $\Large \sigma$  this is sigma. Useful for normal or gaussian distribution $$\Large f(x) = \frac{1}{\sigma \sqrt{2*\pi}} exp^{-1/2}(\frac{x-\mu}{\sigma})^2$$ 
- calculus on vectors to understand how to move vectors in a space of fitting parameters and find the values that minimize sum of squares residuals and then the best fitting parameters for the data. For a gaussian that would be to find the values of $\Large \mu$ and $\Large \sigma$ that best describe a Gaussin distribution
- Vector math --> calculus --> machine learning
- Doing vector addition is just the sum of each compenent of the $\Large ij_{th}$ element of the vector, something like $\large a = \begin{bmatrix} 2 \\ 3\end{bmatrix}$ and $\large b = \begin{bmatrix} -1 \\ 4\end{bmatrix}$, $\large a + b = \begin{bmatrix} 1 \\ 7\end{bmatrix}$. Vector addition, since it's done component by component it's called *associative*
 
 ## Questions
- Item



